jobName: "ExampleSparkJob"
master: "local[*]"
appName: "Spark Ingest Transform Sink Job"
javaClass: "com.example.sparkjob.MainClass"
dependencies:
  - "path/to/your/jarfile.jar"
configurations:
  spark.executor.memory: "2g"
  spark.driver.memory: "1g"
  spark.executor.cores: "2"
steps:
  - name: "Ingest"
    type: "read"
    format: "csv"
    options:
      path: "path/to/input/data.csv"
      header: "true"
      inferSchema: "true"
  - name: "Transform"
    type: "transformation"
    operations:
      - operation: "filter"
        condition: "columnA > 10"
      - operation: "select"
        columns: ["columnA", "columnB", "columnC"]
      - operation: "withColumn"
        column: "newColumn"
        expression: "columnA + columnB"
  - name: "Sink"
    type: "write"
    format: "parquet"
    options:
      path: "path/to/output/data"
      mode: "overwrite"
